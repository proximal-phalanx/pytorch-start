{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "dtype = th.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quadratic(th.nn.Module):\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        super(Quadratic, self).__init__()\n",
    "        self.A = th.nn.Parameter(th.randn(n, n))\n",
    "        self.b = th.nn.Parameter(th.randn(n))\n",
    "        self.c = th.nn.Parameter(th.randn(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * th.einsum(\"ij,bi,bj->b\", self.A, x, x) + th.einsum(\"i,bi->b\", self.b, x) + self.c\n",
    "\n",
    "    def string(self):\n",
    "        return f\"0.5 * x^T {self.A} x + {self.b}^T x + {self.c}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientOptimizer(th.optim.Optimizer):\n",
    "    \n",
    "    def __init__(self, params, lr) -> None:\n",
    "        super().__init__(params, {})\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self, closure=None):\n",
    "        with th.no_grad():\n",
    "            for group in self.param_groups:\n",
    "                for p in group['params']:\n",
    "                    if p.grad is None:\n",
    "                        continue\n",
    "                    d = p.grad\n",
    "                    p.add_(-d, alpha=self.lr)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = th.nn.Sequential(\n",
    "    th.nn.Linear(2, 10),\n",
    "    th.nn.ReLU(),\n",
    "    th.nn.Linear(10, 10),\n",
    "    th.nn.ReLU(),\n",
    "    Quadratic(10),\n",
    ").to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use and as data\n",
    "X = th.tensor([[0, 0], [1, 1], [0, 1], [1, 0]], device=device, dtype=dtype)\n",
    "Y = th.tensor([0, 0, 0, 1], device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3920, 0.3726, 0.4757, 0.2120], device='mps:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236fdc1743ec4efd8b25ba5cb1fe67ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 99: Loss 8.540403939605312e-08\n",
      "Step 199: Loss 1.3522516439934407e-13\n",
      "Step 299: Loss 6.994405055138486e-15\n",
      "Step 399: Loss 1.3877787807814457e-15\n",
      "Step 499: Loss 3.219646771412954e-15\n",
      "Step 599: Loss 2.4980018054066022e-15\n",
      "Step 699: Loss 1.942890293094024e-15\n",
      "Step 799: Loss 1.1657341758564144e-15\n",
      "Step 899: Loss 1.1657341758564144e-15\n",
      "Step 999: Loss 3.3306690738754696e-16\n"
     ]
    }
   ],
   "source": [
    "optimizer = GradientOptimizer(model.parameters(), lr=1e-1)\n",
    "\n",
    "steps = 1000\n",
    "logging_steps = 100\n",
    "\n",
    "for step in trange(steps):\n",
    "    optimizer.zero_grad()\n",
    "    loss = th.nn.functional.mse_loss(model(X), Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % logging_steps == logging_steps - 1:\n",
    "        print(f\"Step {step}: Loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "['0.0000', '0.0000', '-0.0000', '1.0000']\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:\")\n",
    "print(\n",
    "    list(\n",
    "        map(\n",
    "            lambda x: \"{:.4f}\".format(x), \n",
    "            model(X).detach().cpu().numpy().tolist()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
